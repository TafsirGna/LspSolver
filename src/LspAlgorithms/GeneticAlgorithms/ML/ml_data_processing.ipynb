{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8a46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print((df1.iloc[:, 152]).value_counts())\n",
    "\n",
    "# # clearing the variables to free my RAM space\n",
    "# del df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ce4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting the big csv file in multiple csv files according each instance\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# loading data\n",
    "datasetDirPath = \"../../../../data/ML/sets\"\n",
    "filePath = datasetDirPath + \"dataset0.csv\"\n",
    "df0 = pd.read_csv(filePath)\n",
    "\n",
    "# getting all changeOverCost values\n",
    "allChangeOverCosts = (df0[\"changeover_costs\"]).unique()\n",
    "\n",
    "for index, changeOverCosts in enumerate(allChangeOverCosts):\n",
    "    df_i = df0.loc[df0['changeover_costs'] == changeOverCosts]\n",
    "    df_i.to_csv(datasetDirPath + str(index) + \".csv\", index=False)\n",
    "\n",
    "# # clearing the variables to free my RAM space\n",
    "# del df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a03df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding instance index to pandas df\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/\"\n",
    "listFiles = os.listdir(datasetDirPath)\n",
    "\n",
    "for file in listFiles:\n",
    "    filePath = datasetDirPath + file\n",
    "    instanceIndex = file.replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(filePath)\n",
    "    df[\"instance_file_root_name\"] = instanceIndex\n",
    "    # df = df.iloc[:, 1:]\n",
    "    df.to_csv(filePath, index=False)\n",
    "    # print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b2d200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the test set and the training set\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/preproc/\"\n",
    "fileRootName = datasetDirPath + \"1\"\n",
    "filePath = fileRootName + \".csv\"\n",
    "strat_train_set_file_path = fileRootName + \"_train_set.csv\"\n",
    "strat_test_set_file_path = fileRootName + \"_test_set.csv\"\n",
    "\n",
    "df = pd.read_csv(filePath)\n",
    "# i'm insterested only in the 100,000 first entries\n",
    "df = df.iloc[:100000, :]\n",
    "\n",
    "# print(df.iloc[:, -1].value_counts())\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "strat_train_set, strat_test_set = (None, None)\n",
    "for train_index, test_index in split.split(df, df.iloc[:, -1]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "    \n",
    "strat_train_set.to_csv(strat_train_set_file_path, index=False)\n",
    "strat_test_set.to_csv(strat_test_set_file_path, index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926c54ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ... False  True False]\n",
      "[[17483  4233]\n",
      " [ 1009 57275]]\n",
      "0.9311796839435521\n",
      "0.9826882163200878\n"
     ]
    }
   ],
   "source": [
    "# training with general ml classifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/preproc/\"\n",
    "fileRootName = datasetDirPath + \"1\"\n",
    "strat_train_set_file_path = fileRootName + \"_train_set.csv\"\n",
    "\n",
    "df = pd.read_csv(strat_train_set_file_path)\n",
    "\n",
    "# corr_matrix = df.iloc[:, :19].corr()\n",
    "# print(corr_matrix)\n",
    "\n",
    "training_data_labels = (df.iloc[:, -1] > ) \n",
    "training_data = df.iloc[:, :-1]\n",
    "\n",
    "# df.head()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "training_data = pd.DataFrame(scaler.fit_transform(training_data))\n",
    "\n",
    "# training a model on the data collected\n",
    "# sgd_clf = SGDClassifier(random_state=42)\n",
    "# sgd_clf.fit(training_data, training_data_labels)\n",
    "\n",
    "# trying to predict one's output\n",
    "\n",
    "# y_train_pred = cross_val_predict(sgd_clf, training_data, training_data_labels, cv=7)\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, training_data, training_data_labels, cv=7, method=\"predict_proba\")\n",
    "\n",
    "y_train_pred = (y_probas_forest[:, 1] > .5)\n",
    "print(y_train_pred)\n",
    "\n",
    "print(confusion_matrix(training_data_labels, y_train_pred))\n",
    "\n",
    "print(precision_score(training_data_labels, y_train_pred))\n",
    "\n",
    "print(recall_score(training_data_labels, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "562a794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "79995    1\n",
      "79996    0\n",
      "79997    0\n",
      "79998    1\n",
      "79999    0\n",
      "Name: False, Length: 80000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# training with a Deep Neural network\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/preproc/\"\n",
    "fileRootName = datasetDirPath + \"1\"\n",
    "strat_train_set_file_path = fileRootName + \"_train_set.csv\"\n",
    "\n",
    "df = pd.read_csv(strat_train_set_file_path)\n",
    "\n",
    "# corr_matrix = df.iloc[:, :19].corr()\n",
    "# print(corr_matrix)\n",
    "\n",
    "training_data_labels = (df.iloc[:, -1].replace({True: 1, False: 0}))\n",
    "training_data = df.iloc[:, :-1]\n",
    "\n",
    "# sns.pairplot(training_data, hue='Class')\n",
    "\n",
    "# sns.heatmap(training_data.corr(), annot=True)\n",
    "\n",
    "print(training_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b4784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
