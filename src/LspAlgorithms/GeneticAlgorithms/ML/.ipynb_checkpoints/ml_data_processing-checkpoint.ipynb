{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8a46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print((df1.iloc[:, 152]).value_counts())\n",
    "\n",
    "# # clearing the variables to free my RAM space\n",
    "# del df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ce4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting the big csv file in multiple csv files according each instance\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# loading data\n",
    "datasetDirPath = \"../../../../data/ML/sets\"\n",
    "filePath = datasetDirPath + \"dataset0.csv\"\n",
    "df0 = pd.read_csv(filePath)\n",
    "\n",
    "# getting all changeOverCost values\n",
    "allChangeOverCosts = (df0[\"changeover_costs\"]).unique()\n",
    "\n",
    "for index, changeOverCosts in enumerate(allChangeOverCosts):\n",
    "    df_i = df0.loc[df0['changeover_costs'] == changeOverCosts]\n",
    "    df_i.to_csv(datasetDirPath + str(index) + \".csv\", index=False)\n",
    "\n",
    "# # clearing the variables to free my RAM space\n",
    "# del df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a03df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding instance index to pandas df\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/\"\n",
    "listFiles = os.listdir(datasetDirPath)\n",
    "\n",
    "for file in listFiles:\n",
    "    filePath = datasetDirPath + file\n",
    "    instanceIndex = file.replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(filePath)\n",
    "    df[\"instance_file_root_name\"] = instanceIndex\n",
    "    # df = df.iloc[:, 1:]\n",
    "    df.to_csv(filePath, index=False)\n",
    "    # print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b2d200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the test set and the training set\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/preproc/\"\n",
    "fileRootName = datasetDirPath + \"1\"\n",
    "filePath = fileRootName + \".csv\"\n",
    "strat_train_set_file_path = fileRootName + \"_train_set.csv\"\n",
    "strat_test_set_file_path = fileRootName + \"_test_set.csv\"\n",
    "\n",
    "df = pd.read_csv(filePath)\n",
    "# i'm insterested only in the 100,000 first entries\n",
    "df = df.iloc[:100000, :]\n",
    "\n",
    "# print(df.iloc[:, -1].value_counts())\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "strat_train_set, strat_test_set = (None, None)\n",
    "for train_index, test_index in split.split(df, df.iloc[:, -1]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "    \n",
    "strat_train_set.to_csv(strat_train_set_file_path, index=False)\n",
    "strat_test_set.to_csv(strat_test_set_file_path, index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926c54ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.783913\n",
      "1    -1.976529\n",
      "2    -1.922316\n",
      "3     0.582775\n",
      "4    -0.587196\n",
      "5    -0.783717\n",
      "6     1.485101\n",
      "7     2.098917\n",
      "8     0.041536\n",
      "9    -0.114813\n",
      "10   -0.728343\n",
      "11    0.657330\n",
      "12    0.104938\n",
      "13    0.062541\n",
      "14   -1.066141\n",
      "15    0.269452\n",
      "16   -0.690053\n",
      "17    1.230676\n",
      "18    0.237706\n",
      "19    1.040354\n",
      "20   -0.783000\n",
      "21   -0.628524\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "datasetDirPath = \"../../../../data/ML/sets/preproc/\"\n",
    "fileRootName = datasetDirPath + \"1\"\n",
    "strat_train_set_file_path = fileRootName + \"_train_set.csv\"\n",
    "\n",
    "df = pd.read_csv(strat_train_set_file_path)\n",
    "\n",
    "# corr_matrix = df.iloc[:, :19].corr()\n",
    "# print(corr_matrix)\n",
    "\n",
    "training_data_labels = df.iloc[:, -1]\n",
    "training_data = df.iloc[:, :-1]\n",
    "\n",
    "# df.head()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "training_data = pd.DataFrame(scaler.fit_transform(training_data))\n",
    "\n",
    "# training a model on the data collected\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(training_data, training_data_labels)\n",
    "\n",
    "# trying to predict one's output\n",
    "\n",
    "# print(training_data.iloc[0, :])\n",
    "sgd_clf.predict([training_data.iloc[0, :]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
